
# Kafka 스터디 질의 응답 정리

---

## 💾 주제: 메시지 저장 및 자원 관리

Q ) **Kafka에서 발행하는 메시지는 물리적인 disk 에 저장되는걸로 알고 있는데요, HDD 인지 SSD 인지 궁금하네요.**  
> Kafka는 브로커 로컬 디스크에 메시지를 저장하며, 운영 환경에서는 성능과 안정성을 위해 SSD 사용이 사실상 필수다.

Q ) **PageCache 에 대해서 아시나요 ? 비유도 궁금하네요.**  
> OS에서 디스크 접근 속도를 높이기 위해 사용하는 메모리 캐시 이다.  
> 라면 가게의 앞치마에 재료를 미리 넣어두는 것처럼, Kafka는 Page Cache를 활용해 디스크 I/O를 최소화 한다.

Q ) **Kafka를 단독으로 구성하는 것이 권장되는 이유?**  
> Kafka는 디스크, 네트워크, Page Cache 등 자원 사용량이 매우 크기 때문에, 다른 앱과 함께 배포 시 캐시 경쟁과 I/O 병목이 발생할 수 있다.  
> 메모리를 폭력적으로 쓰기 때문에 성능을 기대하려면 메모리를 독점해야 한다.

4. **Kafka는 실제로, CPU를 많이 쓰겠네요?**  
> 메시지 압축, 직렬화, 복제, 체크섬 계산 등의 작업으로 인해 CPU 사용량이 높습니다. TPS가 높거나 압축 알고리즘이 무거울수록 더욱 크다.

---

## 🧱 주제: Kafka 아키텍처 및 클라우드 전략

Q ) **앙상블(ensemble)이랑 레플리카(replica)의 차이가 정확히 뭘까요?**  
> 앙상블은 컨트롤러 메타데이터 합의 그룹(Zookeeper 또는 KRaft)을 의미하며, 레플리카는 각 파티션의 데이터 복제본을 말한다.  
> 앙상블은 메시지를 저장하거나 처리하지 않는다 ! 다시말해 **“리더 역할을 누가 맡을지 정하는 집단”**.  
> 레플리카는 결정된 리더/팔로워 역할에 따라 실제 Kafka 메시지를 저장하고 클라이언트 요청을 처리하는 쪽 !

| 비유             | Kafka 개념                          |
|----------------| --------------------------------- |
| 스터디 운영진 3명     | **앙상블 (Zookeeper or Controller)** |
| 운영진이 리더 발표자 정함 | **파티션 리더 브로커 선출**                 |
| 리더가 실제 발표함     | **리더 레플리카가 메시지 처리**               |
| 다른 팀원이 따라 정리함  | **팔로워 레플리카가 복제 (sync)**           |

Q ) **Kafka를 보통 클라우드 환경에 두나요?**  
> 온프레미스 환경일 수도 있고, AWS, GCP, Azure 등 클라우드 환경에 구성 가능하며, MSK, Confluent Cloud 같은 관리형 서비스도 활용된다.

Q ) **Kafka를 AWS에서 쓰면 비용이 만만치 않겠네요 ?**  
> Yes. 비용이 빠르게 증가할 수 있다.

Q ) **오.. 그럼 TPS가 20일 때 클라우드 환경에서 대략적인 비용이 얼만지 궁금하긴 하네요**  
> 재미로 ) 구성에 따라 다를수 있지만 대략  
> 
> EC2 직접 구성 -> ₩15만 원 이하  
> AWS MSK -> 약 ₩40만 원   
> Confluent Cloud -> ₩30만 원 이상   

Q ) **TPS가 2000일 때도 궁금하네요**  
> AWS MSK (강력한 복제 및 안정성 고려) -> ₩330~470만 원  
> EC2 직접 구성 (비용 최적화 + 커스터마이징 자유) -> ₩250~350만 원  
> Confluent Cloud (완전관리형 SaaS) -> ₩330~500만 원  

---

## 📤 메시지 전송, 멱등성 및 중복 방지

Q ) **Fire-and-Forget이 뭔가요?**  
 > `acks=0` 설정으로, Kafka 브로커의 응답을 기다리지 않고 메시지를 전송하는 방식이다. 속도는 빠르지만 신뢰성은 낮다.

Q ) **DLQ는 누가 발행 할까요?**  
 > Kafka가 자동 발행하는 것이 아니라, 메시지 처리 실패를 감지한 애플리케이션이 DLQ 토픽에 직접 전송해야 한다.

Q ) **DLQ 자체도 장애가 나면 어떻게 대응해야 할까요?**  
 > DLQ 전송 실패 시 로컬 로그 저장, S3 fallback, Prometheus 알림 등 이중 보호 전략이 필요하다.

Q ) **Kafka에서 메시지 중복 발행 케이스가 있나요?**  
 > 네트워크 오류, Producer 재시도, 설정 오류 등으로 중복이 발생할 수 있다.

Q ) **Kafka에서 멱등성 제어는 브로커가 하나요?**  
 > Yes 브로커가 Producer ID와 시퀀스를 기준으로 중복 메시지를 감지하고 차단한다.

Q ) **멱등성 설정은 Producer 에서 해야하나요 ? Broker 에서 해야하나요?**  
 > 설정은 Producer에서 하고, 실제 중복 감지는 Broker에서 수행한다.

Q ) **그럼에도 불구하고 중복 메시지가 발생할 수 있나?**  
 > Yes.. PID 리셋, 리더 failover, 시퀀스 꼬임 등 예외 상황에서는 멱등성이 무력화될 수 있다.

---

## 🧨 장애 및 복구 시나리오

Q ) **Kafka 클러스터가 다 죽으면 어떻게 대응해야 하나요?**  
 > 브로커와 컨트롤러(Zookeeper 또는 KRaft) 모두 복구되어야 클러스터가 정상화 된다.   
 > 메시지는 디스크에 유지되므로 복구 가능성은 높다.

Q ) **퍼블리셔는 살아있는데 브로커가 하나씩 애매하게 죽는 상황에선 장애 대응을 어떻게 하나?**  
 > 재시도 설정, 리더 재할당, DLQ fallback, under-replicated partition 알림 등을 통해 그레이존 장애를 완화해야 한다.

---

## 🛑 제한 및 제어 전략 (Quota, Throttling)

Q ) **Quota, Throttling은 언제 쓰이는 건가요?**  
> 특정 Producer나 Consumer가 과도하게 리소스를 점유하지 않도록 하기 위해 사용한다. 

Q ) **Kafka 쿼터를 개발자가 일일이 설정해줘야 하나요?**  
 > Yes. 기본값은 무제한이며, 운영자가 `kafka-configs.sh` 또는 Admin API를 통해 명시적으로 설정해야 작동한다.

Q ) **Kafka 설정 변경하려면 브로커 재시작 꼭 해야 해?**  
 > 대부분의 클라이언트, 토픽, 쿼터 설정은 런타임 중 동적 변경 가능하며 재시작이 필요 없다.

Q ) **Kafka 버전마다 설정 방식 차이가 있나?**  
 > Yes. 동적 설정 범위, 멱등성 기본값, Exactly-once 안정성, KRaft 지원 여부 등이 버전에 따라 다르다.

---
